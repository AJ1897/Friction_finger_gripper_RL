EPSILON_MAX: 0.9
TOTAL_EPOCHS: 1700
EPSILON_MIN: 0.001
EXP_FACTOR: 0.75
NUM_CYCLES: 5
MAX_EPISODE: 10
MAX_STEPS: 100
HER_ENABLE: True
FUTURE_K: 4
BOOTSTRAP: False #Set this to true when you want to bootstrap the training from a existing policy
TABLE_GEN: False  #Set this to true when you want to generate a new valid action table for a object size
MODE: 2  # 0 -train 1- test 2- plot
ACTION_TABLE_PATH: './Valid_action_table.txt'
NETWORK_PATH: './checkpoint11.pth'
R_PLOT_PATH:  './Reward10.png'
L_PLOT_PATH:   './Loss10.png'
TENSORBOARD_PATH: './'

#Environment parameters
OBJECT_SIZE: 3
FINGER_START: 7.0
FINGER_END: 11.0

#Model hyper parameters
FC1_units: 64
FC2_units: 64
BUFFER_SIZE: 1000000  # replay buffer size
BATCH_SIZE: 256  # minibatch size
GAMMA: 0.95  #it discount factor
TAU: 1e-3  # for soft update of target parameters
LR: 0.001  # learning rate
UPDATE_EVERY: 10  # how often to update the network
HER_UPDATE_EPISODES: 10
